<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Content Moderation & Enforcement Policy - Liftrix</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #fff;
            padding: 20px;
            max-width: 800px;
            margin: 0 auto;
        }
        h1 {
            font-size: 28px;
            margin-bottom: 10px;
            color: #1a1a1a;
        }
        h2 {
            font-size: 22px;
            margin-top: 30px;
            margin-bottom: 15px;
            color: #2a2a2a;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 5px;
        }
        h3 {
            font-size: 18px;
            margin-top: 20px;
            margin-bottom: 10px;
            color: #3a3a3a;
        }
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        ul, ol {
            margin-left: 25px;
            margin-bottom: 15px;
        }
        li {
            margin-bottom: 8px;
        }
        .effective-date {
            font-style: italic;
            color: #666;
            margin-bottom: 30px;
        }
        .important {
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 20px 0;
        }
        .section {
            margin-bottom: 30px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #f8f9fa;
            font-weight: 600;
        }
        .process-step {
            background-color: #e7f3ff;
            border-left: 4px solid #20C9B7;
            padding: 15px;
            margin: 15px 0;
        }
        a {
            color: #20C9B7;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .placeholder {
            background-color: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <h1>Content Moderation & Enforcement Policy</h1>
    <p class="effective-date">Effective Date: December 30, 2025</p>
    <p class="effective-date">Last Updated: December 30, 2025</p>

    <div class="important">
        <p><strong>Purpose:</strong> This policy describes how Liftrix moderates user-generated content, enforces Community Guidelines, and maintains a safe platform for all users. This policy applies to all content and interactions on the Liftrix platform.</p>
    </div>

    <div class="section">
        <h2>1. Scope and Authority</h2>

        <h3>1.1 Content Subject to Moderation</h3>
        <p>This policy applies to all user-generated content on Liftrix, including:</p>
        <ul>
            <li>Profile information (display names, biographies, profile photos)</li>
            <li>Workout posts and social content</li>
            <li>Comments on posts</li>
            <li>Progress photos and uploaded images</li>
            <li>Messages and communications between users</li>
            <li>AI chat conversations (for abuse prevention purposes)</li>
            <li>Any other content created or shared by users</li>
        </ul>

        <h3>1.2 Moderation Authority</h3>
        <p><span class="placeholder">[Company Name]</span> reserves the right to:</p>
        <ul>
            <li>Review any content on the platform at any time</li>
            <li>Remove or hide content that violates our policies</li>
            <li>Suspend or terminate user accounts for policy violations</li>
            <li>Make final decisions on content disputes</li>
            <li>Update moderation policies as needed</li>
        </ul>

        <h3>1.3 Applicable Policies</h3>
        <p>Content moderation is guided by:</p>
        <ul>
            <li>Community Guidelines</li>
            <li>Terms of Service</li>
            <li>This Content Moderation Policy</li>
            <li>Applicable laws and regulations</li>
            <li>Google Play Developer Program Policies</li>
        </ul>
    </div>

    <div class="section">
        <h2>2. Moderation Systems and Methods</h2>

        <h3>2.1 Automated Moderation</h3>
        <p>We employ automated systems that:</p>
        <ul>
            <li>Screen content for prohibited material before publication</li>
            <li>Detect patterns of abusive behavior</li>
            <li>Identify spam and repetitive content</li>
            <li>Monitor rate of content posting to prevent flooding</li>
            <li>Track user reports and engagement metrics</li>
        </ul>
        <p>Automated systems may automatically hide or flag content for human review but do not make final decisions on account actions.</p>

        <h3>2.2 User Reporting</h3>
        <p>Users can report content through in-app reporting mechanisms. Reports trigger review by our moderation team. The reporting system includes:</p>
        <ul>
            <li>Report reasons (spam, harassment, inappropriate content, etc.)</li>
            <li>Optional description field for additional context</li>
            <li>Anonymous reporting (reporter identity not disclosed to reported user)</li>
            <li>Duplicate report detection (users cannot report same content repeatedly)</li>
        </ul>

        <h3>2.3 Volume-Based Automatic Actions</h3>
        <p>Content that receives multiple reports from different users may be:</p>
        <ul>
            <li>Automatically hidden from public view pending review (threshold: 5 unique reports)</li>
            <li>Prioritized for moderation team review</li>
            <li>Evaluated for pattern violations</li>
        </ul>
        <p>Automatic hiding is temporary and does not constitute a final determination. Content is reviewed by human moderators before permanent action is taken.</p>

        <h3>2.4 Human Review</h3>
        <p>Our moderation team conducts manual review of:</p>
        <ul>
            <li>User-reported content</li>
            <li>Content flagged by automated systems</li>
            <li>Appeals of moderation decisions</li>
            <li>Complex or nuanced policy violations</li>
            <li>Accounts with repeated violations</li>
        </ul>

        <h3>2.5 Proactive Monitoring</h3>
        <p>We may proactively review content to:</p>
        <ul>
            <li>Identify emerging abuse patterns</li>
            <li>Ensure policy compliance</li>
            <li>Improve automated detection systems</li>
            <li>Address platform-wide issues</li>
        </ul>
    </div>

    <div class="section">
        <h2>3. Report Review Process</h2>

        <div class="process-step">
            <h3>Step 1: Report Submission</h3>
            <p>User submits report through in-app mechanism or email</p>
            <ul>
                <li>Report logged in moderation queue</li>
                <li>Reporter receives confirmation message</li>
                <li>Content may be automatically hidden if multiple reports received</li>
            </ul>
        </div>

        <div class="process-step">
            <h3>Step 2: Initial Assessment</h3>
            <p>Moderation team reviews report within 24 hours</p>
            <ul>
                <li>Content examined in context</li>
                <li>Relevant policies identified</li>
                <li>Severity level determined</li>
                <li>User history reviewed</li>
            </ul>
        </div>

        <div class="process-step">
            <h3>Step 3: Decision and Action</h3>
            <p>Moderator determines appropriate action</p>
            <ul>
                <li>No violation: Content restored (if hidden), report dismissed</li>
                <li>Violation confirmed: Action taken according to enforcement matrix</li>
                <li>Ambiguous case: Escalated to senior moderator</li>
            </ul>
        </div>

        <div class="process-step">
            <h3>Step 4: User Notification</h3>
            <p>Affected parties notified of outcome</p>
            <ul>
                <li>Content creator notified of content removal or account action</li>
                <li>Reporter notified that action has been taken (without specific details)</li>
                <li>Explanation of violation provided when content removed</li>
            </ul>
        </div>

        <div class="process-step">
            <h3>Step 5: Appeal Period</h3>
            <p>User may appeal decision within 14 days</p>
            <ul>
                <li>Appeals reviewed by different moderator</li>
                <li>Additional context considered</li>
                <li>Decision confirmed or reversed</li>
            </ul>
        </div>

        <h3>3.1 Review Timeline</h3>
        <p>We aim to:</p>
        <ul>
            <li>Acknowledge reports within 1 hour (automated confirmation)</li>
            <li>Begin review within 24 hours of report submission</li>
            <li>Complete initial review within 48 hours for most cases</li>
            <li>Prioritize severe violations (threats, illegal content) for immediate review</li>
            <li>Respond to appeals within 5 business days</li>
        </ul>
        <p>These are target timelines and may vary based on report volume and complexity.</p>
    </div>

    <div class="section">
        <h2>4. Enforcement Actions</h2>

        <h3>4.1 Content-Level Actions</h3>
        <p>Actions that may be taken against specific content:</p>

        <table>
            <tr>
                <th>Action</th>
                <th>Description</th>
                <th>Impact</th>
            </tr>
            <tr>
                <td><strong>Content Removal</strong></td>
                <td>Content permanently deleted from platform</td>
                <td>Content no longer visible; cannot be restored</td>
            </tr>
            <tr>
                <td><strong>Content Hiding</strong></td>
                <td>Content hidden from public but retained for review</td>
                <td>Only visible to creator and moderators; may be restored</td>
            </tr>
            <tr>
                <td><strong>Visibility Restriction</strong></td>
                <td>Content limited to followers or private</td>
                <td>Reduced audience; content remains accessible to some users</td>
            </tr>
            <tr>
                <td><strong>Comment Disabling</strong></td>
                <td>Comments disabled on specific post</td>
                <td>Prevents further discussion on problematic content</td>
            </tr>
        </table>

        <h3>4.2 Account-Level Actions</h3>
        <p>Actions that may be taken against user accounts:</p>

        <h4>Warning</h4>
        <ul>
            <li><strong>Applied for:</strong> First-time minor violations, unintentional breaches</li>
            <li><strong>Impact:</strong> Educational notification sent; no functional restrictions</li>
            <li><strong>Duration:</strong> Permanent record; influences future enforcement decisions</li>
            <li><strong>User action:</strong> Expected to acknowledge and correct behavior</li>
        </ul>

        <h4>Temporary Posting Restriction</h4>
        <ul>
            <li><strong>Applied for:</strong> Repeated minor violations, single moderate violation</li>
            <li><strong>Impact:</strong> Limited ability to create posts, comments, or messages</li>
            <li><strong>Duration:</strong> 24 hours to 30 days (based on severity)</li>
            <li><strong>User action:</strong> Can view content but cannot contribute new content</li>
        </ul>

        <h4>Temporary Account Suspension</h4>
        <ul>
            <li><strong>Applied for:</strong> Serious violations, multiple moderate violations</li>
            <li><strong>Impact:</strong> Complete loss of access to account</li>
            <li><strong>Duration:</strong> 7 to 90 days (based on severity and history)</li>
            <li><strong>User action:</strong> Cannot access platform; account data preserved</li>
        </ul>

        <h4>Permanent Account Ban</h4>
        <ul>
            <li><strong>Applied for:</strong> Severe violations, illegal activity, repeated serious offenses</li>
            <li><strong>Impact:</strong> Permanent removal from platform; account may be deleted</li>
            <li><strong>Duration:</strong> Permanent; user prohibited from creating new accounts</li>
            <li><strong>User action:</strong> May request data export before final deletion; cannot be reinstated</li>
        </ul>

        <h3>4.3 Enforcement Matrix</h3>
        <p>Enforcement decisions consider:</p>
        <ul>
            <li><strong>Violation severity:</strong> Minor, moderate, serious, severe</li>
            <li><strong>User history:</strong> First offense vs. repeat violations</li>
            <li><strong>Intent:</strong> Accidental, negligent, or deliberate</li>
            <li><strong>Harm caused:</strong> Extent of impact on other users or platform</li>
            <li><strong>Context:</strong> Circumstances surrounding the violation</li>
            <li><strong>Response:</strong> User cooperation and willingness to correct behavior</li>
        </ul>
    </div>

    <div class="section">
        <h2>5. Specific Violation Categories</h2>

        <h3>5.1 Harassment and Bullying</h3>
        <p><strong>Typical actions:</strong></p>
        <ul>
            <li>First offense: Warning to permanent ban (depending on severity)</li>
            <li>Targeted harassment: Immediate 7-day suspension minimum</li>
            <li>Severe harassment (threats, doxxing): Immediate permanent ban</li>
            <li>Repeat harassment after warning: Permanent ban</li>
        </ul>

        <h3>5.2 Hate Speech and Discrimination</h3>
        <p><strong>Typical actions:</strong></p>
        <ul>
            <li>Hate speech: Immediate content removal + 30-day suspension minimum</li>
            <li>Severe or repeated hate speech: Permanent ban</li>
            <li>Organized hate activity: Permanent ban + reporting to authorities if applicable</li>
        </ul>

        <h3>5.3 Sexually Explicit Content</h3>
        <p><strong>Typical actions:</strong></p>
        <ul>
            <li>Borderline inappropriate: Content removal + warning</li>
            <li>Explicit content: Content removal + 7-day suspension</li>
            <li>Repeated violations: Permanent ban</li>
            <li>Sexual solicitation: Immediate permanent ban</li>
        </ul>

        <h3>5.4 Spam and Commercial Abuse</h3>
        <p><strong>Typical actions:</strong></p>
        <ul>
            <li>Minor promotional content: Content removal + warning</li>
            <li>Repeated spam: 7-day posting restriction</li>
            <li>Aggressive commercial activity: 30-day suspension</li>
            <li>Coordinated spam operation: Permanent ban</li>
        </ul>

        <h3>5.5 Dangerous Content</h3>
        <p><strong>Typical actions:</strong></p>
        <ul>
            <li>Dangerous exercise advice: Content removal + warning to 7-day suspension</li>
            <li>Promotion of eating disorders: Content removal + 30-day suspension</li>
            <li>Promotion of illegal substances: Permanent ban</li>
            <li>Self-harm content: Content removal + wellness resources provided</li>
        </ul>

        <h3>5.6 Impersonation and Fraud</h3>
        <p><strong>Typical actions:</strong></p>
        <ul>
            <li>Minor misrepresentation: Warning + requirement to correct</li>
            <li>Impersonation: Immediate permanent ban</li>
            <li>Fake credentials: Content removal + 30-day suspension to permanent ban</li>
            <li>Fraudulent activity: Permanent ban + reporting to authorities</li>
        </ul>

        <h3>5.7 Platform Manipulation</h3>
        <p><strong>Typical actions:</strong></p>
        <ul>
            <li>Circumventing restrictions: Extension of restriction period</li>
            <li>Creating alternate accounts to bypass ban: Permanent ban of all accounts</li>
            <li>Automated abuse or bot activity: Immediate permanent ban</li>
            <li>Exploiting platform vulnerabilities: Permanent ban</li>
        </ul>
    </div>

    <div class="section">
        <h2>6. Appeals Process</h2>

        <h3>6.1 Eligibility for Appeal</h3>
        <p>Users may appeal:</p>
        <ul>
            <li>Content removal decisions</li>
            <li>Account warnings, restrictions, or suspensions</li>
            <li>Permanent bans (in exceptional circumstances)</li>
        </ul>
        <p>Appeals must be submitted within 14 days of the enforcement action.</p>

        <h3>6.2 How to Appeal</h3>
        <p>To appeal a moderation decision:</p>
        <ol>
            <li>Send email to <span class="placeholder">[Support Email]</span> with subject "Moderation Appeal"</li>
            <li>Include your username and account email address</li>
            <li>Specify which action you are appealing</li>
            <li>Explain why you believe the decision was incorrect</li>
            <li>Provide any relevant context or evidence</li>
        </ol>

        <h3>6.3 Appeal Review Process</h3>
        <p>Appeals are reviewed by a different moderator than the one who made the original decision. The review process includes:</p>
        <ul>
            <li>Re-examination of the content and context</li>
            <li>Consideration of user explanation and evidence</li>
            <li>Assessment of whether policies were correctly applied</li>
            <li>Evaluation of any new information provided</li>
        </ul>

        <h3>6.4 Appeal Outcomes</h3>
        <p>Possible outcomes of an appeal:</p>
        <ul>
            <li><strong>Appeal granted:</strong> Action reversed; content restored or account reinstated</li>
            <li><strong>Appeal partially granted:</strong> Action reduced (e.g., suspension shortened)</li>
            <li><strong>Appeal denied:</strong> Original decision upheld</li>
            <li><strong>Additional action:</strong> Further review reveals additional violations</li>
        </ul>

        <h3>6.5 Appeal Decision Timeline</h3>
        <p>We aim to:</p>
        <ul>
            <li>Acknowledge appeals within 24 hours</li>
            <li>Complete appeal review within 5 business days</li>
            <li>Provide written explanation of appeal decision</li>
        </ul>

        <h3>6.6 Finality of Decisions</h3>
        <p>Appeal decisions are final. Users may submit a second appeal only if:</p>
        <ul>
            <li>New evidence becomes available that was not previously considered</li>
            <li>There is clear indication of procedural error</li>
        </ul>
        <p>Repeated appeals without new information may not be reviewed.</p>
    </div>

    <div class="section">
        <h2>7. Transparency and Accountability</h2>

        <h3>7.1 Moderation Team Standards</h3>
        <p>Our moderation team operates under the following principles:</p>
        <ul>
            <li><strong>Consistency:</strong> Apply policies uniformly across all users</li>
            <li><strong>Impartiality:</strong> Make decisions based on policy, not personal opinions</li>
            <li><strong>Context awareness:</strong> Consider cultural context and intent</li>
            <li><strong>Privacy:</strong> Protect user privacy while conducting reviews</li>
            <li><strong>Continuous improvement:</strong> Learn from mistakes and update practices</li>
        </ul>

        <h3>7.2 Reporting to Users</h3>
        <p>We provide transparency through:</p>
        <ul>
            <li>Specific explanation when content is removed</li>
            <li>Citation of violated policy provisions</li>
            <li>Information on appeal rights</li>
            <li>General notification to reporters that action has been taken</li>
        </ul>

        <h3>7.3 Platform Transparency</h3>
        <p>We may publish periodic transparency reports including:</p>
        <ul>
            <li>Number of reports received</li>
            <li>Types of violations detected</li>
            <li>Enforcement actions taken</li>
            <li>Appeal statistics</li>
        </ul>
        <p>Individual user data is not disclosed in transparency reports.</p>
    </div>

    <div class="section">
        <h2>8. Special Circumstances</h2>

        <h3>8.1 Imminent Danger</h3>
        <p>If content indicates imminent risk of harm to self or others:</p>
        <ul>
            <li>Content is immediately escalated to senior moderation</li>
            <li>We may contact emergency services if appropriate</li>
            <li>User is provided with crisis resources</li>
            <li>Account may be temporarily locked pending safety assessment</li>
        </ul>

        <h3>8.2 Illegal Activity</h3>
        <p>If content involves illegal activity:</p>
        <ul>
            <li>Content is immediately removed</li>
            <li>Account is suspended pending investigation</li>
            <li>We may cooperate with law enforcement as required by law</li>
            <li>Legal process documentation is preserved</li>
        </ul>

        <h3>8.3 Minor Safety</h3>
        <p>For content involving users under 18:</p>
        <ul>
            <li>Enhanced scrutiny applied to interactions with adults</li>
            <li>Suspected exploitation is immediately escalated and reported</li>
            <li>Parents/guardians may be contacted in cases of concern</li>
            <li>Additional protective measures may be implemented</li>
        </ul>

        <h3>8.4 Coordinated Attacks</h3>
        <p>If we detect coordinated harassment or manipulation:</p>
        <ul>
            <li>All participating accounts investigated</li>
            <li>Pattern analysis conducted</li>
            <li>Mass enforcement action may be taken</li>
            <li>Protective measures implemented for targeted users</li>
        </ul>
    </div>

    <div class="section">
        <h2>9. User Tools and Controls</h2>

        <h3>9.1 Self-Moderation Tools</h3>
        <p>Users have access to tools for managing their own experience:</p>
        <ul>
            <li><strong>Privacy settings:</strong> Control who can view and interact with content</li>
            <li><strong>Blocking:</strong> Prevent specific users from viewing or interacting with you</li>
            <li><strong>Comment filtering:</strong> Disable comments on your posts</li>
            <li><strong>Content deletion:</strong> Remove your own content at any time</li>
        </ul>

        <h3>9.2 Reporting Tools</h3>
        <p>Users can report violations through:</p>
        <ul>
            <li>In-app report button on posts, comments, and profiles</li>
            <li>Email to moderation team</li>
            <li>Detailed report categories for accurate routing</li>
        </ul>

        <h3>9.3 Support Resources</h3>
        <p>Users can access:</p>
        <ul>
            <li>Community Guidelines documentation</li>
            <li>FAQ and help articles</li>
            <li>Direct support through <span class="placeholder">[Support Email]</span></li>
            <li>Crisis resources and hotline information (for mental health concerns)</li>
        </ul>
    </div>

    <div class="section">
        <h2>10. Policy Updates</h2>
        <p>This Content Moderation Policy may be updated to:</p>
        <ul>
            <li>Reflect changes in platform features</li>
            <li>Address emerging abuse patterns</li>
            <li>Comply with legal requirements</li>
            <li>Incorporate community feedback</li>
            <li>Improve clarity and effectiveness</li>
        </ul>
        <p>Material changes will be communicated through in-app notifications and email. Continued use of the platform after updates constitutes acceptance of the revised policy.</p>
    </div>

    <div class="section">
        <h2>11. Contact Information</h2>
        <p>For questions about content moderation or to report violations:</p>
        <p>
            <strong>Moderation Team Email:</strong> <span class="placeholder">[Support Email]</span><br>
            <strong>Emergency/Safety Concerns:</strong> Contact immediately via email with "URGENT" in subject line
        </p>
        <p>For general support or policy questions, see our Support & Contact page.</p>
    </div>

    <hr style="margin: 40px 0; border: none; border-top: 1px solid #e0e0e0;">
    <p style="font-size: 12px; color: #999; text-align: center;">
        Document Version 1.0 | Last Updated: December 30, 2025
    </p>
</body>
</html>